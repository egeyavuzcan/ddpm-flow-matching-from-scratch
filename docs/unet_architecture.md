# UNet Architecture Deep Dive

This document provides a detailed explanation of the UNet architecture implemented for our diffusion models.

---

## ğŸ“ General Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           UNet Architecture                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   INPUTS                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚   â”‚  x (noisy)   â”‚  â”‚      t       â”‚  â”‚ class_label  â”‚                      â”‚
â”‚   â”‚ (B,3,32,32)  â”‚  â”‚    (B,)      â”‚  â”‚    (B,)      â”‚                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚          â”‚                 â”‚                  â”‚                              â”‚
â”‚          â”‚                 â–¼                  â–¼                              â”‚
â”‚          â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚          â”‚          â”‚   Time + Class Embedding    â”‚                         â”‚
â”‚          â”‚          â”‚      (B,) â†’ (B, 256)        â”‚                         â”‚
â”‚          â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚          â”‚                         â”‚                                         â”‚
â”‚          â–¼                         â”‚ (emb broadcast to all blocks)          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚                                        â”‚
â”‚   â”‚   conv_in    â”‚                 â”‚                                        â”‚
â”‚   â”‚  3 â†’ 64 ch   â”‚                 â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚                                        â”‚
â”‚          â”‚                         â”‚                                        â”‚
â”‚          â–¼                         â”‚                                        â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚         ENCODER (Downsampling Path)                                         â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚          â”‚                         â”‚                                        â”‚
â”‚          â–¼                         â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    skipâ‚       â”‚                                        â”‚
â”‚   â”‚ ResBlockÃ—2   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                        â”‚
â”‚   â”‚  64 â†’ 64     â”‚                â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                                        â”‚
â”‚   â”‚  Downsample  â”‚  32Ã—32 â†’ 16Ã—16 â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    skipâ‚‚       â”‚                                        â”‚
â”‚   â”‚ ResBlockÃ—2   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                        â”‚
â”‚   â”‚  64 â†’ 128    â”‚                â”‚                                        â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚                                        â”‚
â”‚   â”‚ Attention?   â”‚ (if res=16)    â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                                        â”‚
â”‚   â”‚  Downsample  â”‚  16Ã—16 â†’ 8Ã—8   â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    skipâ‚ƒ       â”‚                                        â”‚
â”‚   â”‚ ResBlockÃ—2   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                        â”‚
â”‚   â”‚ 128 â†’ 256    â”‚                â”‚                                        â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚                                        â”‚
â”‚   â”‚ Attention    â”‚ (res=8 âœ“)      â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â”‚                        â”‚                                        â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚         MIDDLE (Bottleneck)                                                 â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚          â”‚                        â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                                        â”‚
â”‚   â”‚  ResBlock    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ (emb)                                  â”‚
â”‚   â”‚  256 â†’ 256   â”‚                â”‚                                        â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚                                        â”‚
â”‚   â”‚ Attention    â”‚                â”‚                                        â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚                                        â”‚
â”‚   â”‚  ResBlock    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ (emb)                                  â”‚
â”‚   â”‚  256 â†’ 256   â”‚                â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                                        â”‚
â”‚          â”‚                        â”‚                                        â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚         DECODER (Upsampling Path)                                           â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚          â”‚                        â”‚                                        â”‚
â”‚          â–¼                        â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                                        â”‚
â”‚   â”‚  cat(h,skip) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ skipâ‚ƒ                                â”‚
â”‚   â”‚ ResBlock Ã—3  â”‚                                                         â”‚
â”‚   â”‚ 256+256â†’256  â”‚                                                         â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                                         â”‚
â”‚   â”‚ Attention    â”‚                                                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚   Upsample   â”‚  8Ã—8 â†’ 16Ã—16                                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚  cat(h,skip) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ skipâ‚‚                               â”‚
â”‚   â”‚ ResBlock Ã—3  â”‚                                                         â”‚
â”‚   â”‚ 256+128â†’128  â”‚                                                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚   Upsample   â”‚  16Ã—16 â†’ 32Ã—32                                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚  cat(h,skip) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ skipâ‚                               â”‚
â”‚   â”‚ ResBlock Ã—3  â”‚                                                         â”‚
â”‚   â”‚ 128+64 â†’ 64  â”‚                                                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â”‚                                                                  â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚         OUTPUT                                                              â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚          â”‚                                                                  â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚  GroupNorm   â”‚                                                         â”‚
â”‚   â”‚    SiLU      â”‚                                                         â”‚
â”‚   â”‚  conv_out    â”‚  64 â†’ 3                                                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â”‚                                                                  â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚   â”‚   OUTPUT     â”‚                                                         â”‚
â”‚   â”‚ (B,3,32,32)  â”‚  â† predicted noise (DDPM) or velocity (Flow Matching)   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Detailed Component Explanation

### 1. Time Embedding (Sinusoidal Position Embedding)

**Purpose:** Provide the model with information about "what t we are currently at".

**Why is it important?**
- `t=0`: Image is nearly clean, little noise.
- `t=999`: Pure Gaussian noise, model must predict everything.
- Without this information, the model cannot distinguish between different noise levels!

**Formula:**
```
PE(t, 2i) = sin(t / 10000^(2i/dim))
PE(t, 2i+1) = cos(t / 10000^(2i/dim))
```

**Shape Flow:**
```
Input:  t = (B,)           # Batch of timesteps, e.g., [0, 500, 999, 100]
        â†“
Sinusoidal: (B, dim)       # e.g., (4, 256)
        â†“
MLP: Linear â†’ SiLU â†’ Linear
        â†“
Output: (B, dim)           # e.g., (4, 256) - ready to broadcast
```

**Code:**
```python
# embeddings.py
class SinusoidalPositionEmbedding(nn.Module):
    def forward(self, timesteps):
        # timesteps: (B,) â†’ (B, dim)
        freqs = exp(-log(10000) * arange(dim/2) / (dim/2))
        args = timesteps[:, None] * freqs[None, :]
        return cat([sin(args), cos(args)], dim=-1)
```

---

### 2. Class Embedding (nn.Embedding)

**Purpose:** Provide the model with information about "which class to generate".

**Why is it important?**
- Unconditional: Generates a random CIFAR-10 image.
- Conditional: You can say "generate a CAT for me".

**Shape Flow:**
```
Input:  class_label = (B,)     # e.g., [0, 5, 3, 9] (cat, dog, bird, truck)
        â†“
nn.Embedding(10, dim)
        â†“
Output: (B, dim)               # e.g., (4, 256)
```

**Time + Class Combination:**
```python
t_emb = time_embed(t)         # (B, 256)
c_emb = class_embed(c)        # (B, 256)
combined = t_emb + c_emb      # (B, 256) - elementwise addition
```

---

### 3. ResidualBlock

**Purpose:** Feature extraction + time conditioning.

**Why residual?**
- Facilitates gradient flow.
- Provides training stability in deep networks.
- `h + skip` formula: what is learned is the "residual" (difference).

**Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ResidualBlock             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  x â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  GroupNorm â†’ SiLU â†’ Conv3Ã—3      â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  + t_emb[:,:,None,None] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚                     broadcast â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  GroupNorm â†’ SiLU â†’ Dropout      â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Conv3Ã—3                         â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  + â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”‚         skip connection             â”‚
â”‚  â–¼                                     â”‚
â”‚  output                                â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Shape Flow:**
```
Input:  x = (B, C_in, H, W)      # e.g., (4, 64, 32, 32)
        t_emb = (B, dim)          # e.g., (4, 256)
        â†“
Conv3Ã—3: (B, C_in, H, W) â†’ (B, C_out, H, W)
        â†“
+ t_emb[:,:,None,None]: time conditioning broadcast
        â†“
Conv3Ã—3: keeps spatial size
        â†“
+ skip_conv(x): residual connection
        â†“
Output: (B, C_out, H, W)         # e.g., (4, 128, 32, 32)
```

---

### 4. Downsample / Upsample

**Purpose:** Change spatial resolution.

**Downsample (Encoder):**
```
Input:  (B, C, 32, 32)
        â†“
Conv2d(stride=2, kernel=3, padding=1)
        â†“
Output: (B, C, 16, 16)   # Spatial size halved
```

**Upsample (Decoder):**
```
Input:  (B, C, 16, 16)
        â†“
F.interpolate(scale_factor=2, mode='nearest')
        â†“
Conv2d(kernel=3, padding=1)
        â†“
Output: (B, C, 32, 32)   # Spatial size doubled
```

---

### 5. Self-Attention

**Purpose:** Capture global dependencies.

**Why is it needed?**
- Convolution is only local (3Ã—3 or 5Ã—5 neighborhood).
- It cannot see the relationship between distant pixels.
- Attention: "How related is this pixel to that distant pixel?"

**Where is it used?**
- At low resolutions (8Ã—8, 16Ã—16).
- Too expensive at high resolution: O(NÂ²) where N = HÃ—W.

**Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Self-Attention              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  x â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  GroupNorm                       â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Conv1Ã—1 â†’ Q, K, V               â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Reshape: (B,C,H,W) â†’ (B,heads,N,d)    â”‚
â”‚  â”‚         where N = HÃ—W         â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Attention = softmax(QÂ·K^T / âˆšd) â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Output = Attention Â· V          â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Reshape: (B,heads,N,d) â†’ (B,C,H,W)    â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  Conv1Ã—1 (projection)            â”‚     â”‚
â”‚  â”‚                               â”‚     â”‚
â”‚  â–¼                               â”‚     â”‚
â”‚  + â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”‚         residual                    â”‚
â”‚  â–¼                                     â”‚
â”‚  output                                â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Shape Flow:**
```
Input:  x = (B, C, H, W)         # e.g., (4, 256, 8, 8)
        â†“
Reshape: (B, C, 64) â†’ (B, heads, 64, head_dim)
        â†“
Q, K, V projections
        â†“
Attention: (B, heads, 64, 64)    # NÃ—N attention matrix
        â†“
Apply to V: (B, heads, 64, head_dim)
        â†“
Reshape back: (B, C, 8, 8)
        â†“
Output: (B, C, H, W)             # e.g., (4, 256, 8, 8) - same shape!
```

---

### 6. Skip Connections

**Purpose:** Transfer information from Encoder to Decoder.

**Why is it important?**
- Fine details are lost during downsampling.
- Skip connections preserve these details.
- This is the structure that forms the "U" shape!

**Visual:**
```
ENCODER                              DECODER
â”€â”€â”€â”€â”€â”€â”€â”€                             â”€â”€â”€â”€â”€â”€â”€â”€
[64ch, 32Ã—32] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º cat([h, skip]) â†’ ResBlock
      â†“                                    â†‘
   Downsample                          Upsample
      â†“                                    â†‘
[128ch, 16Ã—16] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º cat([h, skip]) â†’ ResBlock
      â†“                                    â†‘
   Downsample                          Upsample
      â†“                                    â†‘
[256ch, 8Ã—8] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º cat([h, skip]) â†’ ResBlock
      â†“                                    â†‘
      â””â”€â”€â”€â”€â”€â”€â”€â–º MIDDLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Channel Concatenation:**
```python
# Before each ResBlock in Decoder:
h = (B, 256, 8, 8)      # Current hidden state
skip = (B, 256, 8, 8)   # From encoder
h = torch.cat([h, skip], dim=1)  # â†’ (B, 512, 8, 8)
h = resblock(h, emb)    # â†’ (B, 256, 8, 8)
```

---

## ğŸ“Š Full Forward Pass: Shape Tracking

```python
# Example: B=4, CIFAR-10 (32Ã—32), base_channels=64, channel_mults=(1,2,4)

# INPUTS
x = (4, 3, 32, 32)       # Noisy image
t = (4,)                 # Timesteps [100, 500, 800, 300]
c = (4,)                 # Classes [0, 5, 3, 9]

# EMBEDDINGS
emb = time_class_embed(t, c)   # â†’ (4, 256)

# INITIAL CONV
h = conv_in(x)                 # (4, 3, 32, 32) â†’ (4, 64, 32, 32)
skips = [h]                    # Store for later

# ENCODER
# Level 0: 64 channels, 32Ã—32
h = resblock(h, emb)           # (4, 64, 32, 32) â†’ (4, 64, 32, 32)
skips.append(h)
h = resblock(h, emb)           # (4, 64, 32, 32) â†’ (4, 64, 32, 32)
skips.append(h)
h = downsample(h)              # (4, 64, 32, 32) â†’ (4, 64, 16, 16)
skips.append(h)

# Level 1: 128 channels, 16Ã—16
h = resblock(h, emb)           # (4, 64, 16, 16) â†’ (4, 128, 16, 16)
skips.append(h)
h = resblock(h, emb)           # (4, 128, 16, 16) â†’ (4, 128, 16, 16)
skips.append(h)
h = downsample(h)              # (4, 128, 16, 16) â†’ (4, 128, 8, 8)
skips.append(h)

# Level 2: 256 channels, 8Ã—8
h = resblock(h, emb)           # (4, 128, 8, 8) â†’ (4, 256, 8, 8)
h = attention(h)               # (4, 256, 8, 8) â†’ (4, 256, 8, 8) â† Attention!
skips.append(h)
h = resblock(h, emb)           # (4, 256, 8, 8) â†’ (4, 256, 8, 8)
h = attention(h)               # (4, 256, 8, 8) â†’ (4, 256, 8, 8)
skips.append(h)

# MIDDLE (Bottleneck)
h = mid_resblock1(h, emb)      # (4, 256, 8, 8) â†’ (4, 256, 8, 8)
h = mid_attention(h)           # (4, 256, 8, 8) â†’ (4, 256, 8, 8)
h = mid_resblock2(h, emb)      # (4, 256, 8, 8) â†’ (4, 256, 8, 8)

# DECODER
# Level 2 â†’ Level 1
skip = skips.pop()             # (4, 256, 8, 8)
h = cat([h, skip], dim=1)      # (4, 256, 8, 8) + (4, 256, 8, 8) â†’ (4, 512, 8, 8)
h = resblock(h, emb)           # (4, 512, 8, 8) â†’ (4, 256, 8, 8)
h = attention(h)
# ... repeat for all skips
h = upsample(h)                # (4, 256, 8, 8) â†’ (4, 256, 16, 16)

# ... continues until original resolution ...

# OUTPUT
h = norm_out(h)                # GroupNorm
h = silu(h)                    # Activation
h = conv_out(h)                # (4, 64, 32, 32) â†’ (4, 3, 32, 32)

# FINAL OUTPUT
output = (4, 3, 32, 32)        # Same shape as input!
                               # This is Îµ (noise) for DDPM
                               # or v (velocity) for Flow Matching
```

---

## ğŸ¯ Summary: Role of Each Component

| Component | Input | Output | Role |
|---------|-------|-------|------|
| **Time Embed** | `(B,)` | `(B, dim)` | Noise level information |
| **Class Embed** | `(B,)` | `(B, dim)` | Class conditioning |
| **conv_in** | `(B,3,H,W)` | `(B,C,H,W)` | Channel projection |
| **ResBlock** | `(B,C,H,W)` | `(B,C',H,W)` | Feature extraction + t cond. |
| **Downsample** | `(B,C,H,W)` | `(B,C,H/2,W/2)` | Reduce resolution |
| **Attention** | `(B,C,H,W)` | `(B,C,H,W)` | Global relationships |
| **Middle** | `(B,C,H,W)` | `(B,C,H,W)` | Bottleneck processing |
| **Upsample** | `(B,C,H,W)` | `(B,C,2H,2W)` | Increase resolution |
| **Skip cat** | `h + skip` | `concat(h,skip)` | Preserve fine details |
| **conv_out** | `(B,C,H,W)` | `(B,3,H,W)` | Final prediction |

---

## ğŸ’¡ Key Insights

1. **Input = Output size:** `(B, 3, 32, 32) â†’ (B, 3, 32, 32)`
   - The model predicts something of the same size as the image.
   - DDPM: noise Îµ
   - Flow Matching: velocity v

2. **t embedding goes to every ResBlock:**
   - Every layer knows "what t we are currently at".
   - This allows the model to learn the difference between t=0 vs t=999.

3. **Attention only at low resolution:**
   - 8Ã—8 = 64 tokens â†’ 64Ã—64 = 4096 attention calculations (OK)
   - 32Ã—32 = 1024 tokens â†’ 1024Ã—1024 = 1M attention calculations (TOO SLOW)

4. **Skip connections are critical:**
   - Without them, the model performs very poorly.
   - Fine spatial details are transferred from encoder to decoder.
